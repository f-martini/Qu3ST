from datetime import datetime
from pathlib import Path
from typing import Any

import numpy as np
from qiskit import QuantumCircuit, ClassicalRegister, QiskitError
import scipy
import logging

from qiskit_ibm_runtime import SamplerV2, QiskitRuntimeService, RuntimeJobV2, RuntimeJob

from ..results_manager import ResultsManager

file_path = Path(Path(__file__).resolve()).parent

logger = logging.getLogger(__name__)
logging.getLogger('qiskit_ibm_runtime').setLevel(logging.ERROR)
logging.getLogger('qiskit.transpiler').setLevel(logging.ERROR)
logging.getLogger('qiskit').setLevel(logging.ERROR)


def log_backend_info(path: Path):
    try:
        with open(path / "backend_info", "w"):
            pass
    except QiskitError:
        print()

    return


def get_pauli_list(H, mapping):
    coeff = np.zeros(len(H))
    obs = ["" for _ in H]
    for idx, h in enumerate(H):
        tmp_h, c = h.to_list()[0]
        coeff[idx] = c.real
        N = len(tmp_h)
        for m in mapping:
            obs[idx] += tmp_h[N - m - 1]
    return obs, coeff


def twirler(q, qc, H, pm, variations, size):
    print(f"Twirling process running", flush=True)
    for i in range(0, variations, size):
        true_size = min(size, variations - i)
        batch = pm(qc, H, true_size)
        q.put(batch)
        print(f"Loaded {i + true_size} circuits.")
    print(f"Twirling process exiting")


def process_results(job_result):
    raw_probs = {}
    raw_counts = {}
    actual_shots = 0
    for n, res in enumerate(job_result):
        data = res.data
        for _, v in data.items():
            for sample, count in v.get_counts().items():
                if sample in raw_counts.keys():
                    raw_counts[sample] += count
                else:
                    raw_counts[sample] = count
                actual_shots += count
    for sample, count in raw_counts.items():
        raw_probs[sample] = count / actual_shots
    return raw_probs, raw_counts, actual_shots


def run_job(base_sampler, tups, shots, callback=None):
    job = base_sampler.run(
        tups, shots=shots
    )
    if callback is not None:
        callback(job)
    job_result = job.result()
    return job_result


def get_sampler_job(
        service: QiskitRuntimeService,
        sampler: SamplerV2,
        pubs: Any,
        shots: int,
        results_manager: ResultsManager | None = None,
        it: int | None = None) -> RuntimeJobV2:

    if (results_manager is not None and
        service is not None and
        it is not None and
        results_manager.exists_job_data(it)):

        job_data = results_manager.load_job_data(it)
        try:
            job = service.job(job_data["id"])
        except Exception:
            logger.exception(f"Job {job_data['id']} failed to load. "
                             f"Generating new one.")
        else:
            if job.status() not in ["ERROR", "JobStatus.ERROR",
                                    "CANCELLED", "JobStatus.CANCELLED"]:
                if isinstance(job, RuntimeJob):
                    raise TypeError(
                        "The job is was not generated by the current algorithm."
                    )
                return job

    job = sampler.run(pubs=pubs, shots=shots)
    if results_manager is not None and results_manager.base_res_path is not None:
        base_tag = results_manager.base_res_path.name
    else:
        base_tag = ""

    if isinstance(job, (RuntimeJobV2, RuntimeJob)):
        job.update_tags([f"{base_tag}_iteration_{it}"])
    update_job_result(job, results_manager, it, ended=False)
    return job


def update_job_result(
        job: RuntimeJobV2,
        results_manager: ResultsManager | None,
        it: int | None,
        ended: bool = False):
    if results_manager is None:
        return
    if ended:
        metrics = job.metrics()
        tsmp_c = metrics["timestamps"]["created"].replace("Z", "+00:00")
        tsmp_r = metrics["timestamps"]["running"].replace("Z", "+00:00")
        usage = metrics["usage"]["quantum_seconds"]
        try:
            time_created = datetime.fromisoformat(tsmp_c)
            time_started = datetime.fromisoformat(tsmp_r)
            time_queue = (time_started - time_created).total_seconds()
        except ValueError:
            time_queue = -1
    else:
        tsmp_c, usage, time_queue = -1, -1, -1

    results_manager.save_job_data(
        {
            "id": job.job_id(),
            "tag": job.tags,
            "created": tsmp_c,
            "device_time": usage,
            "queue_time": time_queue,
            "metrics": job.metrics(),
        },
        it if it is not None else -1,
    )


def remove_measurement(ansatz: QuantumCircuit, exact_measure: bool = True):
    """
    Remove all measurement from ansatz (Qiskit QuantumCircuit)
    """
    if len(ansatz.clbits) > 0 and exact_measure:
        ansatz.remove_final_measurements()


def add_measurement(ansatz: QuantumCircuit, mapping=None):
    """
    Add a layer of measurement and associated classical bits to all the
    qubits of ansatz (Qiskit QuantumCircuit)
    """
    if len(ansatz.clbits) > 0:
        ansatz.remove_final_measurements()
        ansatz.cregs = []
    if mapping is not None:
        ansatz.add_register(ClassicalRegister(len(mapping)))
        ansatz.measure(mapping, ansatz.cregs[-1])
    else:
        ansatz.measure_all()


def get_shots(pauli_weights, precision, N_max=10000):
    N = int(np.sum(pauli_weights ** 2) / (precision ** 2))
    return min(N, N_max)


def get_expected_values_from_samples(samples, H, coeff):
    ev = np.zeros(len(H))
    for i, h in enumerate(H):
        for sample, count in samples.items():
            s_ev = 1
            for idx in range(len(h)):
                if h[idx] == "Z" and sample[idx] == '1':
                    s_ev *= -1 * coeff[i]
                else:
                    s_ev *= 1 * coeff[i]
            ev[i] += s_ev * count
    return ev


def get_rem_confusion_matrix(sampler, Nq, save=False, shots=10000, bknd=None):
    A = np.zeros((2 ** Nq, 2 ** Nq))
    if sampler.backend is None:
        raise ValueError(f"Backend is not defined for the given sampler.")
    if bknd is None:
        bknd = sampler.backend
    for i in range(2 ** Nq):
        print(f"\r{i}/{2 ** Nq}\t", end="")
        qc = QuantumCircuit(Nq, Nq)
        bit_string = np.binary_repr(i, Nq)
        for idx, q in enumerate(bit_string):
            if q == '1':
                qc.x(Nq - idx - 1)
        samples = sampler.run(qc, shots=shots)
        for s in samples.keys():
            s_n = int(s, 2)
            A[s_n, i] = samples[s]
    A_pinv = np.linalg.pinv(A)
    if not np.allclose(A @ A_pinv @ A, A):
        raise ArithmeticError("Pseudo-inverse incorrectly computed.")
    if save:
        res_path = (file_path /
                    "rem" /
                    bknd.backend_name /
                    bknd.backend_version)
        res_path.mkdir(parents=True, exist_ok=True)
        np.save(res_path / f"A_rem_{Nq}.npy", A)
        np.save(res_path / f"Ap_rem_{Nq}.npy", A_pinv)
    return A_pinv


def load_pinv(backend, Nq):
    pinv_path = (file_path /
                 "rem" /
                 backend.backend_name /
                 backend.backend_version /
                 f"Ap_rem_{Nq}.npy")
    if pinv_path.exists():
        return np.load(pinv_path)
    return None


def closest_positive_distribution(quasi_probabilities):
    quasi_probabilities = np.array(quasi_probabilities, dtype=np.float64)
    # prepare candidate solution
    init_guess = quasi_probabilities.clip(min=0)
    init_guess /= np.sum(init_guess)
    # generate scipy optimization model
    num_vars = len(init_guess)
    bounds = scipy.optimize.Bounds(np.zeros(num_vars), np.ones(num_vars))
    # force solution normalization
    normalization = scipy.optimize.LinearConstraint(np.ones(num_vars).T, 1, 1)
    result = scipy.optimize.minimize(
        lambda x: np.linalg.norm(x - quasi_probabilities),
        init_guess,
        bounds=bounds,
        constraints=normalization,
    )
    if not result.success:
        raise ValueError(
            "REM failed to determine the closest positive distribution."
        )
    return result.x
